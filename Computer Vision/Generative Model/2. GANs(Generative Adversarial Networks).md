# **Computer Vision - Generative Model**
# **2. GANs (Generative Adversarial Networks)** 




출처: https://wikidocs.net/146217

# 2-1. Background 📚

- GAN은 2014년, Ian Goodfellow의 "Generative Adversarial Network"라는 논문에서 처음 제시
- 짧은 시간동안 상당한 발전을 보였다.


![img](./img/2-1.png)


</Br>


# 2-2. How GAN works?

![img](./img/2-2.png)


</Br>
</Br>


- 📖 **GAN의 기본 철학** : 복잡한 고차원의 training distribution에서 sampling을 하고싶다.
- 이를 해결하기 위해 , simple distribution(e.g. random noise) 를 샘플링 해서, Training distribution 을 따르는 Transformation을 시킬 수 있는 파라미터를 학습하자! 는 전략

![img](./img/2-3.jpeg)





</Br>

## 2-2-1. Generator and Discriminator








- GAN에는 위조지폐범에 해당하는 **Generator(G, 🥷🏻)** 와 경찰에 해당하는 **Discriminator(D, 👮🏻‍♂️)** 가 존재

  - 🥷🏻 **Generator**는 real data의 distribution을 학습해 fake 데이터를 만드는 일을 합니다.
    - → 최종적으로 이를 Discriminator가 최대한 <U>헷갈리게 하는 것을 목표</U>로 합니다.

  - 👮🏻‍♂️ **Discriminator**는 smaple이 realdata(training)인지 아닌지를 구분합니다.
    - → 최종적으로 Fake 이미지를 최대한 <U>잘 판별하는 것 을 목표</U>로 합니다.


</Br>

![img](./img/2-3.png)



</Br>


## 2-2-2. Adversarial learning



![img](./img/2-5.png)


</Br>




- $p_{data}$:  training data의 distribution
- $p_g (G(z))$: Generator가 만들어낸 이미지의 분포



</Br>

- GAN의 기본 구조 요약
  - (initial로 고정된) G로 생성
  - D로 classify, 업데이트
  - (D를 constant로 만들고) G 업데이트
  - (업데이트 된 상태로 고정된 ) G로 생성
  - D로 classify
  - (D를 constant로 만들고) G 업데이트
  - ...
  - 반복
  - ...
  - 이 과정을 반복하다가 D(x) = 1/2, 즉 discriminator가 구분할 수 없는 상태가 됨. $p_g = p_{data}$










</Br>
</Br>


## 2-2-3. Objective function of GAN

$$\min_\theta \max_\phi V(G_\theta, D_\phi) = \mathbb{E}_{\mathbf{x} \sim p_{data}(\mathbf{x})}[\log D_\phi (\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p_{z}(\mathbf{z})}[\log(1-D_\phi(G_\theta(\mathbf{z})))]$$

